# Serverless Video Processing Pipeline (Cloud/Infra)

**Upload a video ‚Üí pipeline compresses, generates thumbnails, and transcribes ‚Üí ready to stream.**

## üß± Architecture (MVP)
- **S3 (uploads bucket)** ‚Äî raw user uploads.
- **S3 (processed bucket)** ‚Äî H.264/AAC MP4 output (or HLS), public-read **via CloudFront**.
- **S3 (thumbnails bucket)** ‚Äî extracted JPEG/PNG frames.
- **DynamoDB (Videos table)** ‚Äî video metadata & job status.
- **API Gateway + Lambda** ‚Äî issue **pre-signed S3 upload URLs**.
- **S3 Event ‚Üí Lambda** ‚Äî when an object lands in uploads, start the **Step Functions** workflow.
- **Step Functions** orchestrates:
  1) `transcode` (FFmpeg) ‚Üí compressed output to processed bucket
  2) `thumbnail` (FFmpeg) ‚Üí preview image(s) to thumbnails bucket
  3) `transcribe_start` (Amazon Transcribe) ‚Üí starts job
  4) `transcribe_poll` (polls Transcribe) ‚Üí on success, store transcript URI
  5) update DynamoDB status + CloudFront URL

> ‚ö†Ô∏è For FFmpeg in Lambda, attach an **FFmpeg Lambda Layer** (see README below). In production, consider **AWS Elemental MediaConvert** for large/long videos.

## üõ† Stack
- **AWS SAM** (IaC) ‚Äî template-driven deploys
- **Python 3.11 Lambdas** ‚Äî boto3, FFmpeg via layer
- **React (Vite)** ‚Äî simple upload UI using presigned URL
- **CloudFront** ‚Äî CDN in front of processed output

## üöÄ Quick Start
### 1) Prereqs
- AWS CLI configured
- SAM CLI installed (`sam --version`)
- Node 18+ for the web app

### 2) Deploy Infra
```bash
cd infra
sam build
sam deploy --guided
```
Take note of the output API endpoint (for **request_upload_url**) and the **CloudFront domain**.

### 3) Run Web (local)
```bash
cd ../web
npm i
npm run dev
```
Create `.env` in `web/`:
```
VITE_API_BASE=https://<api-id>.execute-api.<region>.amazonaws.com/Prod
```

### 4) Upload Flow
1. Click **Upload** ‚Üí UI asks backend for a **presigned PUT URL**.
2. Browser **PUTs** video directly to the **uploads** S3 bucket.
3. S3 **ObjectCreated** event triggers `on_upload` Lambda ‚Üí starts the **Step Functions** job.
4. State machine runs `transcode` ‚Üí `thumbnail` ‚Üí `transcribe_start`/`transcribe_poll` ‚Üí updates DynamoDB.
5. UI polls DynamoDB via the API (optional extension) to show status and the final **CloudFront playback URL**.

## üß© FFmpeg Layer
- Use a Lambda Layer providing static FFmpeg binaries (e.g., `ffmpeg`, `ffprobe` in `/opt/bin`).
- Example public layers exist on GitHub; or build one with AWS SAM/Container. Update the **`FFMPEG_LAYER_ARN`** parameter during `sam deploy --guided`.

## üîí IAM Notes
- Lambdas need S3 read/write to specific buckets, DynamoDB CRUD on the Videos table, and Transcribe permissions (`transcribe:StartTranscriptionJob`, `transcribe:GetTranscriptionJob`).
- State Machine needs permission to invoke tasks; `on_upload` needs to `StartExecution` on the state machine.

## üì¶ What‚Äôs in here
```
infra/template.yaml        # SAM template with S3/DDB/APIGW/StepFunctions/Lambdas
lambdas/*                  # Python Lambda handlers (scaffold)
web/                       # Vite React app (upload UI)
```

## ‚úÖ Next Steps
- Swap FFmpeg-Lambda for **MediaConvert** (robust, scalable) using `AWS::MediaConvert` job.
- Add **HLS packaging** and CloudFront **signed URLs**.
- Add **list/status API** to fetch video statuses from DynamoDB in the UI.
- Add **CORS** + Auth (Cognito) for a production portal.
